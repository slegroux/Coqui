#!/usr/bin/env bash
set -x

TEST_WAV_FOLDER="/data/en/zs_eval"
MODEL_PATH="/data/en/Models/yourtts_models"
DATA_PATH="/data/en"

# encoding
encoder_config_path="${HOME}/.local/share/tts/tts_models--multilingual--multi-dataset--your_tts/config_se.json"
encoder_path="${HOME}/.local/share/tts/tts_models--multilingual--multi-dataset--your_tts/model_se.pth"

# Models
# model_version="EN_ES_32d_bottleneck_accent_encoder_yourtts_vctk_libritts_webex_speakers_google_es_co_d_vectors-July-14-2022_11+25PM-0000000"
# model_path=${model_version}/keep_checkpoint_220000.pth
# model_version="NOISY_DATA_32d_bottleneck_encoder_EN_ES_yourtts_vctk_libritts_webex_speakers_WITH_NOISE_google_es_co_d_vectors-August-12-2022_09+41PM-0000000"
# model_version="syl20_test-October-18-2022_02+20AM-8a829130"
# model_path=${model_version}/best_model_190381.pth
# model_version="syl20_test-September-03-2022_02+53PM-74441499"
# model_version="yourtts_vctk_libritts_webex_EN_d_vectors-June-17-2022_09+21PM-0000000"
# model_version="32dim_bottleneck_accent_encoder_yourtts_vctk_libritts_webex_speakers_EN_d_vectors-July-05-2022_07+28PM-0000000"
# model_version="32d_bottleneck_encoder_AND_2_TOKEN_32d_GST_EN_ES_yourtts_vctk_libritts_webex_speakers_google_es_co_d_vectors-August-02-2022_10+29PM-0000000"

# DEFAULT
MODEL_PATH="${HOME}/.local/share/tts"
model_version="tts_models--multilingual--multi-dataset--your_tts"
checkpoint="model_file"
# d_vector_file="${MODEL_PATH}/${model_version}/speakers.json"
# d-vector
# d_vector_file="/data/en/webex_speakers/known_speakers_jun_17_model_vctk_libritts_webex_speakers.json"
# d_vector_file="/data/en/webex_speakers/aug_12_model_vctk_libritts_googleesco_webex_speakers_with_noise_en_es.json"
d_vector_file="/home/syl20/.local/share/tts/tts_models--multilingual--multi-dataset--your_tts/speakers.json"

# MAILABS EN/ES
MODEL_PATH="/home/syl20/Src/ass/Coqui/recipes/multilingual/vits_tts"
model_version="yourtts_mailabs_en_es-November-05-2022_12+55AM-c984b278"
checkpoint="checkpoint_259300"


model_checkpoint=${model_version}/${checkpoint}.pth
model_config=${model_version}/config.json

# Input
eval_text="This is not really me speaking. My voice is being generated by a computer."

# for i in {lewis.wav,max.wav,michelle.wav,obama.wav,rishav.wav,queen.wav,sundar.wav}; do
#     python eval/synthesize.py \
#         --speaker_wavs ${TEST_WAV_FOLDER}/${i} \
#         --text "${eval_text}" \
#         --language_idx 'en' \
#         --language_id_file ${MODEL_PATH}/${model_version}/language_ids.json \
#         --out_path data/eval/${model_version}/${checkpoint}/$(basename ${d_vector_file} .json)/${i} \
#         --model_config_path ${MODEL_PATH}/${model_config} \
#         --model_path ${MODEL_PATH}/${model_checkpoint} \
#         --encoder_config_path ${encoder_config_path} \
#         --encoder_path ${encoder_path} \
#         --d_vector_file ${d_vector_file}
# done

for i in {lewis.wav,max.wav,michelle.wav,obama.wav,rishav.wav,queen.wav,sundar.wav}; do
    mkdir -p data/eval/${model_version}/${checkpoint}/$(basename ${d_vector_file} .json)
    tts --speaker_wav ${TEST_WAV_FOLDER}/${i} \
        --text "${eval_text}" \
        --language_idx 'en_US' \
        --language_ids_file_path ${MODEL_PATH}/${model_version}/language_ids.json \
        --out_path data/eval/${model_version}/${checkpoint}/$(basename ${d_vector_file} .json)/${i} \
        --config_path ${MODEL_PATH}/${model_config} \
        --model_path ${MODEL_PATH}/${model_checkpoint} \
        --encoder_config_path ${encoder_config_path} \
        --encoder_path ${encoder_path} \
        --speakers_file_path ${d_vector_file}
done